{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis\n",
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, RandomForestRegressor\n",
    "import sys\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from mrmr import mrmr_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "#import tensorflow as tf\n",
    "#from autokeras import StructuredDataClassifier\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import gc\n",
    "import json\n",
    "from itertools import islice\n",
    "import functools\n",
    "from datetime import date\n",
    "#%matplotlib inline\n",
    "#import mpld3\n",
    "#mpld3.enable_notebook()\n",
    "# rf, pps (https://github.com/8080labs/ppscore), correleation, shapele, mrmr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(normalised=1, weighted=True, title_prepend=True, time_split=0, topics_separate=False):\n",
    "    if time_split %2 !=0:\n",
    "         raise Exception(\"time_split has to be divisble by 2\")\n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/prepend_scores_no_utc.csv\", nrows=3)\n",
    "    cols_to_read = list(df.columns).remove(\"post_text\")\n",
    "    df = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/prepend_scores_no_utc.csv\", nrows=400000, usecols=cols_to_read)\n",
    "    \n",
    "    \n",
    "    if normalised < 2:\n",
    "        df = df[df.columns.drop(list(df.filter(regex=\"_abs\" if normalised == 1 else \"_norm\")))]\n",
    "        \n",
    "\n",
    "    keys = [\"info\", \"yta\", \"nah\", \"esh\", \"nta\"]\n",
    "    weight = \"weighted_\" if weighted else \"\"\n",
    "    values = [\"reactions_\"+weight+k.upper() for k in keys]\n",
    "    acros = dict(zip(keys, values))\n",
    "    \n",
    "    dfs = []\n",
    "    if time_split > 0:\n",
    "        print(\"Data split by date range\")\n",
    "        for i in range(len(spacing)-1):\n",
    "            start = spacing[i]\n",
    "            end = spacing[i+1]\n",
    "            dfs.append(df.loc[start <= df[\"post_created_utc\"] & df[\"post_created_utc\"]<end])\n",
    "    elif topics_separate >0:\n",
    "        \n",
    "        topic_min = df[\"topic_nr\"].min()\n",
    "        topic_max = df[\"topic_nr\"].max()\n",
    "        print(f\"Data split by topic ({topic_min}, {topic_max})\")\n",
    "         \n",
    "        for i in range(topic_min, topic_max+1):\n",
    "            dfs.append(df.loc[df[\"topic_nr\"]==i])\n",
    "    else:\n",
    "        dfs = [df]\n",
    "\n",
    "    print(f\"Number of dataframes: {len(dfs)}\")\n",
    "\n",
    "    return dfs, acros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(y, kind=\"up\", indices=[], verbose=False):\n",
    "    \n",
    "    df_y = pd.DataFrame(data={\"Y\":y})\n",
    "    \n",
    "    if len(indices)>0:\n",
    "        if verbose:\n",
    "            print(f\"Using {len(indices)} indices\")\n",
    "    else:\n",
    "        indices = range(len(indices))\n",
    "        \n",
    "\n",
    "    # Get list of indices for classes that are in the indices array\n",
    "    c0_idx = pd.Series(df_y.loc[df_y[\"Y\"]==0].index.values)\n",
    "    c0_idx = c0_idx[c0_idx.isin(indices)]\n",
    "    c1_idx = pd.Series(df_y.loc[df_y[\"Y\"]==1].index.values)\n",
    "    c1_idx = c1_idx[c1_idx.isin(indices)]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"    Y=0: {c0_idx.shape}\")\n",
    "        print(f\"    Y=1: {c1_idx.shape}\")\n",
    "\n",
    "    if kind == \"up\":\n",
    "        #upsample\n",
    "        if len(c0_idx)>len(c1_idx):\n",
    "            n = len(c0_idx)\n",
    "            c1_idx_sampeled = c1_idx.sample(n=n, random_state = 1, replace=len(c1_idx)<n).values\n",
    "            c0_idx_sampeled = c0_idx.values\n",
    "            if verbose:\n",
    "                print(f\"Upsampling Y=1 with {n} samples\")\n",
    "                \n",
    "        elif len(c0_idx)<len(c1_idx):\n",
    "            n = len(c1_idx)\n",
    "            c0_idx_sampeled = c0_idx.sample(n=n, random_state = 1, replace=len(c0_idx)<n).values\n",
    "            c1_idx_sampeled = c1_idx.values\n",
    "            if verbose:\n",
    "                print(f\"Upsampling Y=0 with {n} samples\")\n",
    "                \n",
    "    elif kind ==\"down\":\n",
    "        #downsample\n",
    "        if len(c0_idx)>len(c1_idx):\n",
    "            n = len(c1_idx)\n",
    "            c0_idx_sampeled = c0_idx.sample(n=n, random_state = 1, replace=len(c0_idx)<n).values\n",
    "            c1_idx_sampeled = c1_idx.values\n",
    "            if verbose:\n",
    "                print(f\"Downsampling Y=0 with {n} samples\")\n",
    "        elif len(c0_idx)<len(c1_idx):\n",
    "            n = len(c0_idx)\n",
    "            c1_idx_sampeled = c1_idx.sample(n=n, random_state = 1, replace=len(c1_idx)<n).values\n",
    "            c0_idx_sampeled = c0_idx.values\n",
    "            if verbose:\n",
    "                print(f\"Downsampling Y=1 with {n} samples\")\n",
    "\n",
    "    all_idx = np.concatenate((c0_idx_sampeled, c1_idx_sampeled), axis=0)\n",
    "    \n",
    "    if verbose:\n",
    "        df_tmp = df_y.iloc[all_idx]\n",
    "        print(f\"   Y=0: {len(df_tmp.loc[df_tmp['Y']==0])}\")\n",
    "        print(f\"   Y=1: {len(df_tmp.loc[df_tmp['Y']==1])}\")\n",
    "    return all_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Memory usage & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_size_fmt(num):\n",
    "    if num<10**3:\n",
    "        return \"{:.2f}{}\".format(num,\"B\")\n",
    "    elif ((num>=10**3)&(num<10**6)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**3),\"KB\")\n",
    "    elif ((num>=10**6)&(num<10**9)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**6),\"MB\")\n",
    "    else:\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**9),\"GB\")\n",
    "\n",
    "\n",
    "def memory_usage():\n",
    "    memory_usage_by_variable=pd.DataFrame({k:sys.getsizeof(v)\\\n",
    "    for (k,v) in globals().items()},index=['Size'])\n",
    "    memory_usage_by_variable=memory_usage_by_variable.T\n",
    "    memory_usage_by_variable=memory_usage_by_variable.sort_values(by='Size',ascending=False).head(10)\n",
    "    memory_usage_by_variable['Size']=memory_usage_by_variable['Size'].apply(lambda x: obj_size_fmt(x))\n",
    "    return memory_usage_by_variable\n",
    "\n",
    "def opposite_jdgmt(judgement):\n",
    "    if judgement == \"nta\":\n",
    "        return \"yta\"\n",
    "    elif judgement == \"nah\":\n",
    "        return \"esh\"\n",
    "    elif judgement == \"yta\":\n",
    "        return \"nta\"\n",
    "    elif judgement ==\"esh\":\n",
    "        return \"nah\"\n",
    "    else:\n",
    "        return judgement\n",
    "    \n",
    "# mapping is either \"clip\", meaning negative votes are just set to 0, or \"oppossite\", meaning we use the mapping table in \"opposite_jdgmt\"\n",
    "def map_negative_values(df, mapping=\"clip\"):\n",
    "    # Seems buggy\n",
    "    if mapping == \"opposite\":\n",
    "        for k in acros.keys():\n",
    "            if k == \"info\":\n",
    "                continue\n",
    "            acr = acros[k]\n",
    "            # create temporary columns containing zeros and only negative votes for each vote type (except info)\n",
    "            df[acr+\"_neg_vals\"] = df[acr]\n",
    "            \n",
    "            df.loc[df[acr+\"_neg_vals\"] > 0] = 0\n",
    "            df.loc[df[acr+\"_neg_vals\"] < 0] = df.loc[df[acr+\"_neg_vals\"] < 0]*-1\n",
    "\n",
    "        for k in acros.keys():\n",
    "            if k == \"info\":\n",
    "                continue\n",
    "            acr = acros[k]\n",
    "            #set negative values to 0 & add opposite judgement votes\n",
    "            \n",
    "            df[acr][df[acr] < 0] = 0\n",
    "            df[acr] = df[acr] + df[opposite_jdgmt(acr)]\n",
    "        \n",
    "    elif mapping ==\"clip\":\n",
    "        for k in acros.keys():\n",
    "            acr = acros[k]\n",
    "            df[acr][df[acr] < 0] = 0\n",
    "            \n",
    "    # finally set all negative info votes to 0\n",
    "    df[df[acros[\"info\"]] < 0] = 0\n",
    "    \n",
    "    print(\"info sum\", df[acros[\"info\"]].min())\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data prediction Classes or Regression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_classes(df, acros, ratio=0.5, verbose=False, predict=\"class\", judgement_weighted=True, mapping=\"clip\"):\n",
    "    if verbose:\n",
    "        print(f\"df original shape {df.shape}\")\n",
    "        \n",
    "    n_rows_old = len(df)\n",
    "    \n",
    "    # Map negative judgements to opposing judgement\n",
    "    # i.e. YTA<->NTA, ESH<->NAH\n",
    "    if judgement_weighted:\n",
    "        df = map_negative_values(df, mapping=mapping)\n",
    "    \n",
    "    if predict==\"class\":   \n",
    "        # We only look at YTA and NTA\n",
    "        df[\"YTA_ratio\"] = df[acros[\"yta\"]]/(df[acros[\"info\"]]+ df[acros[\"yta\"]]+ df[acros[\"nah\"]]+df[acros[\"esh\"]]+df[acros[\"nta\"]])\n",
    "\n",
    "        # drop all rows where the majority is not YTA or NTA\n",
    "        df = df.loc[((df[acros[\"yta\"]] > df[acros[\"info\"]]) & (df[acros[\"yta\"]] > df[acros[\"nah\"]]) & (df[acros[\"yta\"]] > df[acros[\"esh\"]])) | ((df[acros[\"nta\"]] > df[acros[\"info\"]]) & (df[acros[\"nta\"]] > df[acros[\"nah\"]]) & (df[\"reactions_weighted_NTA\"] > df[acros[\"esh\"]]))]\n",
    "        if verbose:\n",
    "            print(f\"Drop all rows where majority is not YTA or NTA {df.shape}\")\n",
    "\n",
    "        #drop all rows that are not \"extreme\" enough\n",
    "        df = df.loc[(1-ratio<=df[\"YTA_ratio\"]) | (df[\"YTA_ratio\"]<=ratio)]\n",
    "        if verbose:\n",
    "            print(f\"Removed {n_rows_old-len(df)} rows b.c. not enough agreement. Now {df.shape}\")\n",
    "\n",
    "        #specifc classes & drop unnecesarry\n",
    "        df[\"Y\"] = np.where(df[acros[\"yta\"]] > df[acros[\"nta\"]], 1,  0) # YTA = Class 1, NTA = class 0\n",
    "        if verbose:\n",
    "            print(df.shape)\n",
    "            \n",
    "    elif predict == \"ratio\":\n",
    "        # Y = asshole ratio(AHR) = (YTA+ESH)/(YTA+ESH+NTA+NAH)\n",
    "        df[\"Y\"] = (df[acros[\"yta\"]]+df[acros[\"esh\"]])/(df[acros[\"yta\"]]+ df[acros[\"nah\"]]+df[acros[\"esh\"]]+df[acros[\"nta\"]])\n",
    "        \n",
    "        #drop NAs & infty\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.dropna()\n",
    "        if verbose:\n",
    "           print(f\"Removed {n_rows_old-len(df)} rows b.c. no votes. Now {df.shape}\")\n",
    "        n_rows_old = len(df)\n",
    "        df = df.loc[(1-ratio<=df[\"Y\"]) | (df[\"Y\"]<=ratio)]\n",
    "        if verbose:\n",
    "            print(f\"Removed {n_rows_old-len(df)} rows b.c. not enough agreement. Now {df.shape}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "     # get list of all columns that contain uppercase vote acronym\n",
    "    vote_acroynms = list(filter(lambda x: any([acr.upper() in x for acr in list(acros.keys())]), list(df.columns)))    \n",
    "    df = df.drop(columns=vote_acroynms+[\"post_text\", \"post_id\", \"post_created_utc\", \"Unnamed: 0\"])\n",
    "\n",
    "    # Removing top 4 most important features leads to 0.66 f1\n",
    "    #df = df.drop(columns=[\"speaker_account_comment_karma\", \"post_num_comments\", \"speaker_account_link_karma\", \"speaker_account_age\"])\n",
    "    if verbose:\n",
    "        print(df.shape)\n",
    "    \n",
    "    X = df.drop(columns=[\"Y\"])\n",
    "    y = df[\"Y\"].to_numpy()\n",
    "\n",
    "    feat_name_lst = list(X.columns)\n",
    "\n",
    "    # scaling\n",
    "    scaler = preprocessing.StandardScaler().fit(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    return X_scaled, y, feat_name_lst    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Where the magic happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGRESSION\n",
      "----\n",
      "SIMPLIFYING\n",
      "Models:\n",
      "  xgboost\n",
      "\n",
      "Classification params:\n",
      "{\n",
      "    \"norm_vals\": [\n",
      "        0\n",
      "    ],\n",
      "    \"weighted_vals\": [\n",
      "        true\n",
      "    ],\n",
      "    \"title_prep_vals\": [\n",
      "        true\n",
      "    ],\n",
      "    \"sampling_vals\": [\n",
      "        \"up\"\n",
      "    ],\n",
      "    \"topics_separate\": false,\n",
      "    \"predict\": \"ratio\",\n",
      "    \"mapping_type\": [\n",
      "        \"clip\",\n",
      "        \"opposite\"\n",
      "    ],\n",
      "    \"ratio\": [\n",
      "        0.5\n",
      "    ]\n",
      "}\n",
      "Number of dataframes: 1\n",
      "nr samples 618203\n",
      "df original shape (618203, 190)\n",
      "info sum 0\n",
      "Removed 493602 rows b.c. no votes. Now (124601, 191)\n",
      "Removed 0 rows b.c. not enough agreement. Now (124601, 191)\n",
      "(124601, 176)\n",
      "Running (1/2):\n",
      "  xgboost_norm=0_title=prep_weighted_ratio=0.5_clip\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df original shape (618203, 191)\n",
      "info sum 0\n",
      "Removed 618203 rows b.c. no votes. Now (0, 195)\n",
      "Removed 0 rows b.c. not enough agreement. Now (0, 195)\n",
      "(0, 176)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 175)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_246/2523846093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mmpt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjudgement_weighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                             \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_246/1375992481.py\u001b[0m in \u001b[0;36mget_data_classes\u001b[0;34m(df, acros, ratio, verbose, predict, judgement_weighted, mapping)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# scaling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name_lst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \"\"\"\n\u001b[1;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[1;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no_validation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[1;32m    727\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 175)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "FORCE_SIMPLIFY = True\n",
    "SHOW_SHAPLY = True\n",
    "SHOW_PREDICTION_DISTRIBUTION = True\n",
    "FEAT_IMPORTANCE_N = 50\n",
    "\n",
    "params = {\n",
    "    \"norm_vals\": [0,1,2],               # normalised: 0 = only \"abs\", 1 = only \"norm\", 2 = norm and abs\n",
    "    \"weighted_vals\" : [True, False],     # weighted_vals: whether votes should be weighted by comment score FALSE IS BETTER 0.32\n",
    "    \"title_prep_vals\" : [True],   # title_prepend: whether to use the title prepended or standalone dataset\n",
    "    \"sampling_vals\" : [\"up\", \"down\"],   # sampling_vals: which type of sampling should be done\n",
    "    \"topics_separate\": False,           # if each topic should be analysed separately\n",
    "    \"predict\":\"ratio\",                  # should we predict \"class\" (classification for binary) or \"ratio\" (regression for AHR)\n",
    "    \"mapping_type\":[\"clip\", \"opposite\"], # should we \"clip\" negative votes or map them to the \"opposite\"\n",
    "    \"ratio\": [0.5, 0.4,0.3, 0.2, 0.1, 0.05 ]      # which most extreme AHR or YTA_ratio we want to predict\n",
    "}\n",
    "\n",
    "\n",
    "print(\"CLASSIFICATION\\n----\" if params[\"predict\"]==\"class\" else \"REGRESSION\\n----\")\n",
    "if FORCE_SIMPLIFY:\n",
    "    print(\"SIMPLIFYING\")\n",
    "    for k, v in params.items():\n",
    "        if isinstance(v, list):\n",
    "            params[k] = [v[0]]\n",
    "\n",
    "if params[\"predict\"] == \"ratio\":\n",
    "    params[\"sampling_vals\"] = [\"up\"]\n",
    "\n",
    "params[\"mapping_type\"] = [\"clip\", \"opposite\"]\n",
    "\n",
    "# mpc = MLPClassifier( random_state=1) seems pretty shitty\n",
    "# boost = GradientBoostingClassifier(n_estimators=300, learning_rate=1.0,max_depth=20, random_state=0)\n",
    "xgboost = xgb.XGBClassifier(verbosity = 0) if params[\"predict\"] == \"class\" else xgb.XGBRegressor(verbosity = 0)\n",
    "rfc = RandomForestClassifier(n_estimators= 766, min_samples_split= 2, min_samples_leaf= 1, max_features=\"auto\", max_depth= 40, bootstrap= False, n_jobs=-1) if params[\"predict\"] == \"class\" else RandomForestRegressor(n_estimators= 766, min_samples_split= 2, min_samples_leaf= 1, max_features=\"auto\", max_depth= 40, bootstrap= False, n_jobs=-1)\n",
    "\n",
    "#classifiers = [(boost,\"boost\"), (xgboost,\"xgboost\"), (rfc,\"rfc\")]\n",
    "classifiers = [(xgboost, \"xgboost\"),]\n",
    "\n",
    "\n",
    "print(\"Models:\\n\"+\"\\n\".join([\"  \"+str(s) for m,s in classifiers]))\n",
    "print(\"\\nClassification params:\\n\"+str(json.dumps(params, indent = 4)))\n",
    "\n",
    "#cv = KFold(n_splits=SPLITS, random_state=1, shuffle=True)\n",
    "#for train, test in cv.split(X, y):\n",
    "test_scores = {}\n",
    "nr_samples = []\n",
    "class_ratio = [] #only used for classification\n",
    "top_n_features = {}\n",
    "\n",
    "current_iter = 1\n",
    "max_iter = functools.reduce(lambda a, b: a*b, [len(x) if isinstance(x, list) else 1 for x in list(params.values())])\n",
    "for norm in params[\"norm_vals\"]:\n",
    "    for weighted in params[\"weighted_vals\"]:\n",
    "        for title_prep in params[\"title_prep_vals\"]:\n",
    "        \n",
    "            #TODO: shap dependency plot  \n",
    "            if \"dfs\" in locals() or \"dfs\" in globals():\n",
    "                for i in dfs:\n",
    "                    del i\n",
    "            if \"df\" in list(memory_usage().index):\n",
    "                del df\n",
    "                gc.collect()\n",
    "            \n",
    "                \n",
    "            dfs, acros = get_data(normalised=norm, weighted=weighted, title_prepend=title_prep, topics_separate=params[\"topics_separate\"])\n",
    "\n",
    "            print(\"nr samples\",len(dfs[0]))\n",
    "            for smp in params[\"sampling_vals\"]:\n",
    "                for rto in params[\"ratio\"]:\n",
    "                    for mpt in params[\"mapping_type\"]:\n",
    "                        for df in dfs: \n",
    "                            X, y, feat_name_lst = get_data_classes(df, ratio=rto, acros=acros, predict=params[\"predict\"],judgement_weighted=weighted, mapping=mpt, verbose=True)    \n",
    "                            train, test = train_test_split(range(len(X)), test_size=0.33, random_state=42)\n",
    "\n",
    "                            if params[\"predict\"]==\"class\":\n",
    "                                print(\"Doing sampling\")\n",
    "                                train = sampling(y, kind=smp, indices=train, verbose=False)\n",
    "\n",
    "                            for clf_tpl in classifiers:\n",
    "                                clf = clf_tpl[0]\n",
    "                                clf_name = clf_tpl[1]\n",
    "                                clf_name += f\"_norm={norm}\"\n",
    "                                clf_name += \"_title=\" + \"prep\" if title_prep else \"stdal\"\n",
    "                                clf_name += \"_weighted\" if weighted else \"\"\n",
    "                                clf_name += \"_ratio=\"+str(rto)\n",
    "                                if params[\"predict\"] == \"ratio\":\n",
    "                                    clf_name += \"_\"+mpt\n",
    "\n",
    "                                clf_name += \"_topic_\"+str(df[\"topic_nr\"].iloc[0]) if params[\"topics_separate\"] else \"\"                      \n",
    "\n",
    "                                print(f\"Running ({current_iter}/{max_iter*len(dfs)}):\\n  {clf_name}\")\n",
    "\n",
    "                                X_train = X[train, :]\n",
    "                                y_train = y[train]\n",
    "                                X_test = X[test, :]\n",
    "                                y_test = y[test]\n",
    "\n",
    "                                if SHOW_PREDICTION_DISTRIBUTION:\n",
    "                                    plt.hist(y[train], bins=10*32)\n",
    "                                    plt.show()\n",
    "\n",
    "                                clf.fit(X_train, y_train)\n",
    "                                y_pred = clf.predict(X_test)\n",
    "                                \n",
    "                                if SHOW_SHAPLY:\n",
    "                                    #explainer = shap.explainers.GPUTree(clf, X_train)\n",
    "                                    explainer = shap.explainers.Tree(clf, X_train)\n",
    "                                    shap_values = explainer(X_train)\n",
    "                                    shap.summary_plot(shap_values, X_train, feature_names=feat_name_lst, max_display=50)\n",
    "                                    \n",
    "                                    # save top N features\n",
    "                                    shapely_abs = np.absolute(shap_values)\n",
    "                                    id_sorted = np.argsort(shapely_abs[i])#? why [i]\n",
    "                                    top_n_features[clf_name] = feat_name_lst[id_sorted[:FEAT_IMPORTANCE_N]]\n",
    "                                    top_n_features[clf_name+\" (SHAP SCORES)\"] = shapely_abs[:FEAT_IMPORTANCE_N]\n",
    "                                    \n",
    "\n",
    "\n",
    "                                # We have more Y=0 (NTA) than Y=1 (YTA)\n",
    "                                #metrics.plot_confusion_matrix(classify, X_test, y_test)  \n",
    "                                #plt.show()\n",
    "                                #print(metrics.classification_report(y_test, y_pred, target_names=[\"NTA (0)\", \"YTA (1)\"]))\n",
    "\n",
    "                                if params[\"predict\"] == \"class\":\n",
    "                                    # testing score\n",
    "                                    f1_test = metrics.f1_score(y_test, y_pred, average=\"weighted\")\n",
    "                                    acc_test = metrics.accuracy_score(y_test, y_pred)\n",
    "                                    test_scores[clf_name]=f1_test\n",
    "                                    nr_samples.append(len(X_train))\n",
    "                                    ratio = y[train].sum()/len(y[train])\n",
    "                                    if ratio < 0.5:\n",
    "                                        ratio = (len(y[train])-y[train].sum())/len(y[train])\n",
    "                                    class_ratio.append(ratio)\n",
    "                                    current_iter+=1\n",
    "                                    print(f\"    Accuracy: {acc_test}\\n    F1: {f1_test}\")\n",
    "\n",
    "                                elif params[\"predict\"] == \"ratio\":\n",
    "                                    mean_abs = metrics.mean_absolute_error(y_test, y_pred)\n",
    "                                    mean_sqr = metrics.mean_squared_error(y_test, y_pred)\n",
    "                                    rmse = metrics.mean_squared_error(y_test, y_pred, squared=False)\n",
    "                                    test_scores[clf_name]=rmse\n",
    "                                    nr_samples.append(len(X_train))\n",
    "                                    current_iter+=1\n",
    "                                    print(f\"    Mean absolute: {mean_abs}\\n    Mean squared: {mean_sqr}\\n    Root Mean Squared: {rmse}\")\n",
    " \n",
    "                       \n",
    "#test_scores = np.array(test_scores)\n",
    "#print(f\"Average Test F1: {np.mean(test_scores[:,0])}, Test Accuracy: {np.mean(test_scores[:,1])}\")\n",
    "\n",
    "classifiers = list(test_scores.keys())\n",
    "scores = list(test_scores.values())\n",
    "df_plt = pd.DataFrame({'scores': scores,\n",
    "                       'samples': nr_samples, \n",
    "                        \"class_ratio\":class_ratio if len(class_ratio) > 0 else np.zeros(len(scores))})\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "df_plt['samples'].plot(kind='line', marker='d', secondary_y=True, ylabel=\"# Samples\").set_ylabel(\"# Samples\")\n",
    "df_plt['scores'].plot(kind='bar', color='r', ylabel=\"F1 score\" if params[\"predict\"]==\"class\" else \"RMSE\").set_xticklabels(classifiers) \n",
    "if len(class_ratio)>0:\n",
    "    df_plt['class_ratio'].plot(kind='bar', color='orange')\n",
    "plt.xlabel(\"Classifiers\")\n",
    "ax1.legend([\"Classification\", \"Class Ratios\"])\n",
    "\n",
    "plt.title(\"Comparing \"+(\"F1 \" if params[\"predict\"]==\"class\" else \"RMSE \")+\"of different classifiers\")\n",
    "plt.show()\n",
    "#print(test_scores)\n",
    "\n",
    "print(f'Average : {\"f1 \" if params[\"predict\"]==\"class\" else \"RMSE \"}{np.mean(scores)}')\n",
    "\n",
    "test_scores_lst = list(test_scores.items())\n",
    "\n",
    "srted = sorted(test_scores_lst, key=lambda tup: tup[1])\n",
    "#srted = test_scores_lst.sort(key=lambda x:x[1])\n",
    "print(\"Sorted:\")\n",
    "for c,s in srted:\n",
    "    print(\"   \", c, '->', s)\n",
    "    \n",
    "\n",
    "# For each feature generate a list of all indices where it appears over various classifiers    \n",
    "print(\"Most important features:\")\n",
    "top_feat_val = filter(lambda x: isinstance(x[0], str), list(top_n_features.values()))\n",
    "overal_top_feat = {}\n",
    "for i in range(len(top_feat_val)):\n",
    "    current_top_feats = top_feat_val[i]\n",
    "    for j in range(len(current_top_feats)):\n",
    "        if top_feat_val[i] in overal_top_feat:\n",
    "            overal_top_feat[i] = top_feat_val[i] + [current_top_feats.index(top_feat_val[i])]\n",
    "        else:\n",
    "            overal_top_feat[i] = [current_top_feats.index(top_feat_val[i])]\n",
    "\n",
    "# get overal ranking sum (the one with the smallest ranke is the most important)\n",
    "for i in range(len(overal_top_feat)):\n",
    "    overal_top_feat[i] = sum(overal_top_feat[i])\n",
    "overal_top_feat = dict(sorted(overal_top_feat.items(), key=lambda item: item[1]))\n",
    "\n",
    "top_n_features[\"Overal most important\"] = list(top_feat_val.keys())\n",
    "top_n_features[\"Overal most important (SUM)\"] = list(top_feat_val.values())\n",
    "\n",
    "today = date.today()\n",
    "output = today.strftime(\"%d_%m_%Y\")\n",
    "top_n_features_pd = pd.DataFrame.from_dict(top_n_features)\n",
    "top_n_features.to_excel(output+\".xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Dependency plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"rank(2)\", shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use shap.approximate_interactions to guess which features\n",
    "# may interact with age\n",
    "feature_to_inspect = \"topic_nr\"\n",
    "idx = feat_name_lst.index(feature_to_inspect)\n",
    "inds = shap.approximate_interactions(\"rank(2)\", shap_values, X_train)\n",
    "\n",
    "# make plots colored by each of the top three possible interacting features\n",
    "for i in range(3):\n",
    "    shap.dependence_plot(\"rank(2)\", shap_values, X_train, interaction_index=inds[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 50/50 [00:20<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array(['post_ratio', 'liwc_i', 'liwc_health', 'reactions_is_devil',\n",
      "       'liwc_time', 'liwc_WC', 'speaker_account_age', 'liwc_home',\n",
      "       'writing_sty_profanity_norm', 'foundations_WC', 'liwc_posemo',\n",
      "       'liwc_see', 'liwc_male', 'writing_sty_aita_lst_location',\n",
      "       'writing_sty_is_wibta', 'liwc_sexual', 'liwc_family',\n",
      "       'liwc_negate', 'speaker_author_gender', 'liwc_informal',\n",
      "       'foundations_QMark', 'writing_sty_focus_i_poss_norm', 'liwc_Dic',\n",
      "       'reactions_is_angel', 'writing_sty_self_prof', 'liwc_QMark',\n",
      "       'foundations_05                    IngroupVirtue',\n",
      "       'writing_sty_disgust_norm', 'liwc_relativ',\n",
      "       'writing_sty_other_prof', 'speaker_account_comment_karma',\n",
      "       'writing_sty_aita_avg_location', 'liwc_anx', 'liwc_body',\n",
      "       'liwc_function', 'liwc_netspeak', 'liwc_Authentic', 'liwc_swear',\n",
      "       'liwc_percept', 'liwc_insight', 'liwc_filler',\n",
      "       'writing_sty_focus_i_obj_norm', 'liwc_prep',\n",
      "       'writing_sty_aita_count', 'liwc_focuspresent',\n",
      "       'foundations_11                    MoralityGeneral', 'liwc_Tone',\n",
      "       'liwc_article', 'liwc_motion', 'writing_sty_passive_norm'],\n",
      "      dtype='<U49')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "selected_features = mrmr_classif(X_train, y, K = 50)\n",
    "np_feat_name_lst = np.array(feat_name_lst)\n",
    "pprint(np_feat_name_lst[selected_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "[CV 1/2; 1/50] START bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=377\n",
      "[CV 1/2; 1/50] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=377;, score=0.619 total time= 2.2min\n",
      "[CV 2/2; 1/50] START bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=377\n",
      "[CV 2/2; 1/50] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=377;, score=0.579 total time= 2.4min\n",
      "[CV 1/2; 2/50] START bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000\n",
      "[CV 1/2; 2/50] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=0.516 total time= 3.6min\n",
      "[CV 2/2; 2/50] START bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000\n",
      "[CV 2/2; 2/50] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1000;, score=0.470 total time= 3.6min\n",
      "[CV 1/2; 3/50] START bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688\n",
      "[CV 1/2; 3/50] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688;, score=0.515 total time= 3.8min\n",
      "[CV 2/2; 3/50] START bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688\n",
      "[CV 2/2; 3/50] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688;, score=0.469 total time= 3.8min\n",
      "[CV 1/2; 4/50] START bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000\n",
      "[CV 1/2; 4/50] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=0.629 total time= 8.7min\n",
      "[CV 2/2; 4/50] START bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000\n",
      "[CV 2/2; 4/50] END bootstrap=False, max_depth=30, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1000;, score=0.586 total time= 9.1min\n",
      "[CV 1/2; 5/50] START bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=844\n",
      "[CV 1/2; 5/50] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=844;, score=0.515 total time= 3.1min\n",
      "[CV 2/2; 5/50] START bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=844\n",
      "[CV 2/2; 5/50] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=844;, score=0.468 total time= 3.1min\n",
      "[CV 1/2; 6/50] START bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=533\n",
      "[CV 1/2; 6/50] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=533;, score=0.628 total time= 4.6min\n",
      "[CV 2/2; 6/50] START bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=533\n",
      "[CV 2/2; 6/50] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=533;, score=0.586 total time= 4.9min\n",
      "[CV 1/2; 7/50] START bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611\n",
      "[CV 1/2; 7/50] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611;, score=0.636 total time= 5.5min\n",
      "[CV 2/2; 7/50] START bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611\n",
      "[CV 2/2; 7/50] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611;, score=0.591 total time= 6.1min\n",
      "[CV 1/2; 8/50] START bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=455\n",
      "[CV 1/2; 8/50] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=455;, score=0.638 total time= 4.3min\n",
      "[CV 2/2; 8/50] START bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=455\n",
      "[CV 2/2; 8/50] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=455;, score=0.592 total time= 4.6min\n",
      "[CV 1/2; 9/50] START bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=611\n",
      "[CV 1/2; 9/50] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=611;, score=0.639 total time= 5.7min\n",
      "[CV 2/2; 9/50] START bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=611\n",
      "[CV 2/2; 9/50] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=611;, score=0.593 total time= 6.1min\n",
      "[CV 1/2; 10/50] START bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=922\n",
      "[CV 1/2; 10/50] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=922;, score=0.515 total time= 5.3min\n",
      "[CV 2/2; 10/50] START bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=922\n",
      "[CV 2/2; 10/50] END bootstrap=False, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=922;, score=0.469 total time= 5.2min\n",
      "[CV 1/2; 11/50] START bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=377\n",
      "[CV 1/2; 11/50] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=377;, score=0.605 total time= 2.1min\n",
      "[CV 2/2; 11/50] START bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=377\n",
      "[CV 2/2; 11/50] END bootstrap=True, max_depth=70, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=377;, score=0.564 total time= 2.2min\n",
      "[CV 1/2; 12/50] START bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533\n",
      "[CV 1/2; 12/50] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533;, score=0.638 total time= 4.8min\n",
      "[CV 2/2; 12/50] START bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533\n",
      "[CV 2/2; 12/50] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533;, score=0.592 total time= 5.2min\n",
      "[CV 1/2; 13/50] START bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000\n",
      "[CV 1/2; 13/50] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=0.518 total time= 5.5min\n",
      "[CV 2/2; 13/50] START bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000\n",
      "[CV 2/2; 13/50] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=1000;, score=0.470 total time= 5.4min\n",
      "[CV 1/2; 14/50] START bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=844\n",
      "[CV 1/2; 14/50] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=844;, score=0.519 total time= 4.6min\n",
      "[CV 2/2; 14/50] START bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=844\n",
      "[CV 2/2; 14/50] END bootstrap=False, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=844;, score=0.470 total time= 4.6min\n",
      "[CV 1/2; 15/50] START bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 15/50] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533;, score=0.629 total time= 4.7min\n",
      "[CV 2/2; 15/50] START bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533\n",
      "[CV 2/2; 15/50] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533;, score=0.589 total time= 5.0min\n",
      "[CV 1/2; 16/50] START bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=922\n",
      "[CV 1/2; 16/50] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=922;, score=0.628 total time= 7.8min\n",
      "[CV 2/2; 16/50] START bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=922\n",
      "[CV 2/2; 16/50] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=922;, score=0.585 total time= 8.4min\n",
      "[CV 1/2; 17/50] START bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=455\n",
      "[CV 1/2; 17/50] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=455;, score=0.636 total time= 4.0min\n",
      "[CV 2/2; 17/50] START bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=455\n",
      "[CV 2/2; 17/50] END bootstrap=False, max_depth=70, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=455;, score=0.592 total time= 4.3min\n",
      "[CV 1/2; 18/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611\n",
      "[CV 1/2; 18/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611;, score=0.618 total time= 3.4min\n",
      "[CV 2/2; 18/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611\n",
      "[CV 2/2; 18/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611;, score=0.570 total time= 3.5min\n",
      "[CV 1/2; 19/50] START bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=922\n",
      "[CV 1/2; 19/50] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=922;, score=0.631 total time= 8.1min\n",
      "[CV 2/2; 19/50] START bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=922\n",
      "[CV 2/2; 19/50] END bootstrap=False, max_depth=110, max_features=auto, min_samples_leaf=2, min_samples_split=10, n_estimators=922;, score=0.588 total time= 8.7min\n",
      "[CV 1/2; 20/50] START bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=455\n",
      "[CV 1/2; 20/50] END bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=455;, score=0.618 total time= 2.7min\n",
      "[CV 2/2; 20/50] START bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=455\n",
      "[CV 2/2; 20/50] END bootstrap=True, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=5, n_estimators=455;, score=0.578 total time= 2.9min\n",
      "[CV 1/2; 21/50] START bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=922\n",
      "[CV 1/2; 21/50] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=922;, score=0.633 total time= 8.3min\n",
      "[CV 2/2; 21/50] START bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=922\n",
      "[CV 2/2; 21/50] END bootstrap=False, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=922;, score=0.590 total time= 8.9min\n",
      "[CV 1/2; 22/50] START bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=844\n",
      "[CV 1/2; 22/50] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=844;, score=0.638 total time= 7.7min\n",
      "[CV 2/2; 22/50] START bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=844\n",
      "[CV 2/2; 22/50] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=844;, score=0.593 total time= 8.2min\n",
      "[CV 1/2; 23/50] START bootstrap=True, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=766\n",
      "[CV 1/2; 23/50] END bootstrap=True, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=766;, score=0.607 total time= 4.2min\n",
      "[CV 2/2; 23/50] START bootstrap=True, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=766\n",
      "[CV 2/2; 23/50] END bootstrap=True, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=766;, score=0.569 total time= 4.5min\n",
      "[CV 1/2; 24/50] START bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=922\n",
      "[CV 1/2; 24/50] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=922;, score=0.619 total time= 5.3min\n",
      "[CV 2/2; 24/50] START bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=922\n",
      "[CV 2/2; 24/50] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=922;, score=0.578 total time= 5.7min\n",
      "[CV 1/2; 25/50] START bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=766\n",
      "[CV 1/2; 25/50] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=766;, score=0.638 total time= 7.0min\n",
      "[CV 2/2; 25/50] START bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=766\n",
      "[CV 2/2; 25/50] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=766;, score=0.592 total time= 7.4min\n",
      "[CV 1/2; 26/50] START bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=377\n",
      "[CV 1/2; 26/50] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=377;, score=0.638 total time= 3.4min\n",
      "[CV 2/2; 26/50] START bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=377\n",
      "[CV 2/2; 26/50] END bootstrap=False, max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=377;, score=0.594 total time= 3.7min\n",
      "[CV 1/2; 27/50] START bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=766\n",
      "[CV 1/2; 27/50] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=766;, score=0.639 total time= 7.0min\n",
      "[CV 2/2; 27/50] START bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=766\n",
      "[CV 2/2; 27/50] END bootstrap=False, max_depth=40, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=766;, score=0.594 total time= 7.4min\n",
      "[CV 1/2; 28/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611\n",
      "[CV 1/2; 28/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611;, score=0.612 total time= 3.4min\n",
      "[CV 2/2; 28/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611\n",
      "[CV 2/2; 28/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=611;, score=0.564 total time= 3.5min\n",
      "[CV 1/2; 29/50] START bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000\n",
      "[CV 1/2; 29/50] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=0.626 total time= 8.5min\n",
      "[CV 2/2; 29/50] START bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/2; 29/50] END bootstrap=False, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=10, n_estimators=1000;, score=0.584 total time= 9.1min\n",
      "[CV 1/2; 30/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=688\n",
      "[CV 1/2; 30/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=688;, score=0.614 total time= 3.8min\n",
      "[CV 2/2; 30/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=688\n",
      "[CV 2/2; 30/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=688;, score=0.566 total time= 3.9min\n",
      "[CV 1/2; 31/50] START bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=688\n",
      "[CV 1/2; 31/50] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=688;, score=0.623 total time= 5.7min\n",
      "[CV 2/2; 31/50] START bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=688\n",
      "[CV 2/2; 31/50] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=688;, score=0.574 total time= 5.9min\n",
      "[CV 1/2; 32/50] START bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=533\n",
      "[CV 1/2; 32/50] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=533;, score=0.636 total time= 4.7min\n",
      "[CV 2/2; 32/50] START bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=533\n",
      "[CV 2/2; 32/50] END bootstrap=False, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=533;, score=0.592 total time= 5.0min\n",
      "[CV 1/2; 33/50] START bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533\n",
      "[CV 1/2; 33/50] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533;, score=0.637 total time= 4.9min\n",
      "[CV 2/2; 33/50] START bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533\n",
      "[CV 2/2; 33/50] END bootstrap=False, max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=533;, score=0.592 total time= 5.2min\n",
      "[CV 1/2; 34/50] START bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=533\n",
      "[CV 1/2; 34/50] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=533;, score=0.604 total time= 2.9min\n",
      "[CV 2/2; 34/50] START bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=533\n",
      "[CV 2/2; 34/50] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=533;, score=0.566 total time= 3.1min\n",
      "[CV 1/2; 35/50] START bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=922\n",
      "[CV 1/2; 35/50] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=922;, score=0.606 total time= 5.1min\n",
      "[CV 2/2; 35/50] START bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=922\n",
      "[CV 2/2; 35/50] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=922;, score=0.569 total time= 5.3min\n",
      "[CV 1/2; 36/50] START bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533\n",
      "[CV 1/2; 36/50] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533;, score=0.626 total time= 4.5min\n",
      "[CV 2/2; 36/50] START bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533\n",
      "[CV 2/2; 36/50] END bootstrap=False, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=533;, score=0.580 total time= 4.6min\n",
      "[CV 1/2; 37/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688\n",
      "[CV 1/2; 37/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688;, score=0.611 total time= 3.8min\n",
      "[CV 2/2; 37/50] START bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688\n",
      "[CV 2/2; 37/50] END bootstrap=True, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=688;, score=0.565 total time= 3.9min\n",
      "[CV 1/2; 38/50] START bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=533\n",
      "[CV 1/2; 38/50] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=533;, score=0.621 total time= 3.2min\n",
      "[CV 2/2; 38/50] START bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=533\n",
      "[CV 2/2; 38/50] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=533;, score=0.580 total time= 3.4min\n",
      "[CV 1/2; 39/50] START bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=533\n",
      "[CV 1/2; 39/50] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=533;, score=0.616 total time= 3.0min\n",
      "[CV 2/2; 39/50] START bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=533\n",
      "[CV 2/2; 39/50] END bootstrap=True, max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=533;, score=0.577 total time= 3.2min\n",
      "[CV 1/2; 40/50] START bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=611\n",
      "[CV 1/2; 40/50] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=611;, score=0.617 total time= 3.5min\n",
      "[CV 2/2; 40/50] START bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=611\n",
      "[CV 2/2; 40/50] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=611;, score=0.578 total time= 3.7min\n",
      "[CV 1/2; 41/50] START bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300\n",
      "[CV 1/2; 41/50] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.514 total time= 1.1min\n",
      "[CV 2/2; 41/50] START bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300\n",
      "[CV 2/2; 41/50] END bootstrap=True, max_depth=10, max_features=auto, min_samples_leaf=4, min_samples_split=5, n_estimators=300;, score=0.467 total time= 1.1min\n",
      "[CV 1/2; 42/50] START bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=455\n",
      "[CV 1/2; 42/50] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=455;, score=0.609 total time= 2.6min\n",
      "[CV 2/2; 42/50] START bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=455\n",
      "[CV 2/2; 42/50] END bootstrap=True, max_depth=60, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=455;, score=0.572 total time= 2.7min\n",
      "[CV 1/2; 43/50] START bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=533\n",
      "[CV 1/2; 43/50] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=533;, score=0.606 total time= 2.9min\n",
      "[CV 2/2; 43/50] START bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=533\n",
      "[CV 2/2; 43/50] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=533;, score=0.570 total time= 3.1min\n",
      "[CV 1/2; 44/50] START bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/2; 44/50] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377;, score=0.604 total time= 2.0min\n",
      "[CV 2/2; 44/50] START bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377\n",
      "[CV 2/2; 44/50] END bootstrap=True, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377;, score=0.566 total time= 2.2min\n",
      "[CV 1/2; 45/50] START bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300\n",
      "[CV 1/2; 45/50] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.634 total time= 2.6min\n",
      "[CV 2/2; 45/50] START bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300\n",
      "[CV 2/2; 45/50] END bootstrap=False, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=300;, score=0.590 total time= 2.8min\n",
      "[CV 1/2; 46/50] START bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611\n",
      "[CV 1/2; 46/50] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611;, score=0.619 total time= 3.6min\n",
      "[CV 2/2; 46/50] START bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611\n",
      "[CV 2/2; 46/50] END bootstrap=True, max_depth=110, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=611;, score=0.579 total time= 3.8min\n",
      "[CV 1/2; 47/50] START bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000\n",
      "[CV 1/2; 47/50] END bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000;, score=0.617 total time= 5.7min\n",
      "[CV 2/2; 47/50] START bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000\n",
      "[CV 2/2; 47/50] END bootstrap=True, max_depth=90, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=1000;, score=0.578 total time= 6.1min\n",
      "[CV 1/2; 48/50] START bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377\n",
      "[CV 1/2; 48/50] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377;, score=0.626 total time= 3.2min\n",
      "[CV 2/2; 48/50] START bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377\n",
      "[CV 2/2; 48/50] END bootstrap=False, max_depth=80, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=377;, score=0.585 total time= 3.4min\n",
      "[CV 1/2; 49/50] START bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=688\n",
      "[CV 1/2; 49/50] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=688;, score=0.627 total time= 5.8min\n",
      "[CV 2/2; 49/50] START bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=688\n",
      "[CV 2/2; 49/50] END bootstrap=False, max_depth=70, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=688;, score=0.586 total time= 6.2min\n",
      "[CV 1/2; 50/50] START bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=455\n",
      "[CV 1/2; 50/50] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=455;, score=0.636 total time= 4.0min\n",
      "[CV 2/2; 50/50] START bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=455\n",
      "[CV 2/2; 50/50] END bootstrap=False, max_depth=110, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=455;, score=0.593 total time= 4.3min\n",
      "{'n_estimators': 766, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 40, 'bootstrap': False}\n",
      "F1: 0.3078744819419775, accuracy: 0.7580711920529801\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 300, stop = 1000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "               'max_features':max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "#random_grid = {'n_estimators':[1000],\n",
    "#               'max_features':[\"auto\"],\n",
    "#               'max_depth': [110],\n",
    "#               'min_samples_split': [10],\n",
    "#               'min_samples_leaf': [4],\n",
    "#               'bootstrap': [True]}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 2, verbose=10, random_state=42, n_jobs = 1)\n",
    "# Fit the random search model\n",
    "\n",
    "train, test = train_test_split(range(len(X)), test_size=0.2, random_state=42)\n",
    "train_sampeled = sampling(y, kind=\"up\", indices=train, verbose=False)                  \n",
    "X_train = X[train_sampeled, :]\n",
    "y_train = y[train_sampeled]\n",
    "X_test = X[test, :]\n",
    "y_test = y[test]\n",
    "                   \n",
    "rf_random.fit(X_train, y_train)\n",
    "print(rf_random.best_params_)\n",
    "\n",
    "y_pred  = rf_random.predict(X_test)\n",
    "f1_test = metrics.f1_score(y_test, y_pred)\n",
    "acc_test = metrics.accuracy_score(y_test, y_pred)\n",
    "print(f\"F1: {f1_test}, accuracy: {acc_test}\")\n",
    "# ca 0.85 acc for 300 esimators, rest default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (Deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 10:50:25.081837: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-13 10:50:25.084136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2021-12-13 10:50:25.084164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2080 computeCapability: 7.5\n",
      "coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.23GiB/s\n",
      "2021-12-13 10:50:25.084185: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-13 10:50:25.107041: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-13 10:50:25.107104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-13 10:50:25.121315: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-13 10:50:25.126307: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-13 10:50:25.126376: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2021-12-13 10:50:25.130986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-13 10:50:25.133060: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-13 10:50:25.133071: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-12-13 10:50:25.133473: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-13 10:50:25.133718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-13 10:50:25.133725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-12-13 10:50:25.429626: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-13 10:50:25.433349: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3000005000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2164/2164 [==============================] - 4s 1ms/step - loss: 0.7090 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.4902\n",
      "Epoch 2/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5030 - precision: 0.5028 - recall: 0.5316\n",
      "Epoch 3/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5026 - precision: 0.5026 - recall: 0.4971\n",
      "Epoch 4/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4988 - precision: 0.4988 - recall: 0.4956\n",
      "Epoch 5/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4974 - precision: 0.4973 - recall: 0.4794\n",
      "Epoch 6/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5022 - precision: 0.5021 - recall: 0.5308\n",
      "Epoch 7/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5011 - precision: 0.5011 - recall: 0.5339\n",
      "Epoch 8/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.4954\n",
      "Epoch 9/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5013 - precision: 0.5012 - recall: 0.5336\n",
      "Epoch 10/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5022 - precision: 0.5022 - recall: 0.5022\n",
      "Epoch 11/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5007 - precision: 0.5007 - recall: 0.4914\n",
      "Epoch 12/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5012 - precision: 0.5012 - recall: 0.5147\n",
      "Epoch 13/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5006 - precision: 0.5006 - recall: 0.5140\n",
      "Epoch 14/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5013 - precision: 0.5014 - recall: 0.4925\n",
      "Epoch 15/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5021 - precision: 0.5021 - recall: 0.5026\n",
      "Epoch 16/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.4992 - precision: 0.4993 - recall: 0.5256\n",
      "Epoch 17/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4984 - precision: 0.4985 - recall: 0.5072\n",
      "Epoch 18/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5020 - precision: 0.5020 - recall: 0.5029\n",
      "Epoch 19/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5004 - precision: 0.5004 - recall: 0.5064\n",
      "Epoch 20/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6936 - accuracy: 0.5034 - precision: 0.5034 - recall: 0.4900\n",
      "Epoch 21/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4995 - precision: 0.4994 - recall: 0.4796\n",
      "Epoch 22/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4978 - precision: 0.4977 - recall: 0.4706\n",
      "Epoch 23/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5028 - precision: 0.5028 - recall: 0.4912\n",
      "Epoch 24/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4960 - precision: 0.4959 - recall: 0.4854\n",
      "Epoch 25/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5048 - precision: 0.5046 - recall: 0.5242\n",
      "Epoch 26/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5024 - precision: 0.5025 - recall: 0.4821\n",
      "Epoch 27/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4982 - precision: 0.4980 - recall: 0.4353\n",
      "Epoch 28/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6940 - accuracy: 0.4965 - precision: 0.4964 - recall: 0.4918\n",
      "Epoch 29/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6940 - accuracy: 0.4994 - precision: 0.4994 - recall: 0.5119\n",
      "Epoch 30/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4952 - precision: 0.4950 - recall: 0.4749\n",
      "Epoch 31/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4989 - precision: 0.4989 - recall: 0.5045\n",
      "Epoch 32/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4989 - precision: 0.4989 - recall: 0.4993\n",
      "Epoch 33/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4971 - precision: 0.4970 - recall: 0.4828\n",
      "Epoch 34/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5019 - precision: 0.5019 - recall: 0.5088\n",
      "Epoch 35/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4984 - precision: 0.4985 - recall: 0.5257\n",
      "Epoch 36/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5016 - precision: 0.5018 - recall: 0.4693\n",
      "Epoch 37/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5004 - precision: 0.5004 - recall: 0.4893\n",
      "Epoch 38/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.4987 - precision: 0.4986 - recall: 0.4640\n",
      "Epoch 39/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4972 - precision: 0.4971 - recall: 0.4778\n",
      "Epoch 40/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4982 - precision: 0.4983 - recall: 0.5112\n",
      "Epoch 41/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6940 - accuracy: 0.4995 - precision: 0.4995 - recall: 0.4879\n",
      "Epoch 42/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6940 - accuracy: 0.4962 - precision: 0.4961 - recall: 0.4851\n",
      "Epoch 43/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5030 - precision: 0.5030 - recall: 0.5002\n",
      "Epoch 44/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.4990 - precision: 0.4991 - recall: 0.5134\n",
      "Epoch 45/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4970 - precision: 0.4970 - recall: 0.4924\n",
      "Epoch 46/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4992 - precision: 0.4992 - recall: 0.4877\n",
      "Epoch 47/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5025 - precision: 0.5024 - recall: 0.5099\n",
      "Epoch 48/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5024 - precision: 0.5026 - recall: 0.4650\n",
      "Epoch 49/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6940 - accuracy: 0.4966 - precision: 0.4965 - recall: 0.4832\n",
      "Epoch 50/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4993 - precision: 0.4993 - recall: 0.4960\n",
      "Epoch 51/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5018 - precision: 0.5018 - recall: 0.5231\n",
      "Epoch 52/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.4993 - precision: 0.4993 - recall: 0.4878\n",
      "Epoch 53/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4987 - precision: 0.4986 - recall: 0.4843\n",
      "Epoch 54/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5019 - precision: 0.5017 - recall: 0.5689\n",
      "Epoch 55/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4984 - precision: 0.4983 - recall: 0.4541\n",
      "Epoch 56/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4978 - precision: 0.4978 - recall: 0.5001\n",
      "Epoch 57/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4969 - precision: 0.4969 - recall: 0.4992\n",
      "Epoch 58/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4997 - precision: 0.4997 - recall: 0.4475\n",
      "Epoch 59/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4989 - precision: 0.4990 - recall: 0.5114\n",
      "Epoch 60/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5014 - precision: 0.5013 - recall: 0.5346\n",
      "Epoch 61/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4982 - precision: 0.4981 - recall: 0.4922\n",
      "Epoch 62/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.4996\n",
      "Epoch 63/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4988 - precision: 0.4987 - recall: 0.4812\n",
      "Epoch 64/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4977 - precision: 0.4978 - recall: 0.5171\n",
      "Epoch 65/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4992 - precision: 0.4992 - recall: 0.4868\n",
      "Epoch 66/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4981 - precision: 0.4980 - recall: 0.4579\n",
      "Epoch 67/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5015 - precision: 0.5016 - recall: 0.4844\n",
      "Epoch 68/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4987 - precision: 0.4988 - recall: 0.5075\n",
      "Epoch 69/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5015 - precision: 0.5016 - recall: 0.4723\n",
      "Epoch 70/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4978 - precision: 0.4977 - recall: 0.4627\n",
      "Epoch 71/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4994 - precision: 0.4994 - recall: 0.4975\n",
      "Epoch 72/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.5203\n",
      "Epoch 73/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6936 - accuracy: 0.5037 - precision: 0.5037 - recall: 0.5037\n",
      "Epoch 74/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4991 - precision: 0.4991 - recall: 0.5042\n",
      "Epoch 75/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4993 - precision: 0.4993 - recall: 0.5026\n",
      "Epoch 76/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4992 - precision: 0.4992 - recall: 0.4743\n",
      "Epoch 77/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5009 - precision: 0.5009 - recall: 0.4968\n",
      "Epoch 78/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4994 - precision: 0.4994 - recall: 0.4657\n",
      "Epoch 79/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4973 - precision: 0.4971 - recall: 0.4581\n",
      "Epoch 80/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4997 - precision: 0.4997 - recall: 0.4909\n",
      "Epoch 81/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5003 - precision: 0.5003 - recall: 0.5359\n",
      "Epoch 82/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5008 - precision: 0.5008 - recall: 0.5248\n",
      "Epoch 83/100\n",
      "2164/2164 [==============================] - 4s 2ms/step - loss: 0.6937 - accuracy: 0.5010 - precision: 0.5010 - recall: 0.4931\n",
      "Epoch 84/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5011 - precision: 0.5013 - recall: 0.4498\n",
      "Epoch 85/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5018 - precision: 0.5018 - recall: 0.5013\n",
      "Epoch 86/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4962 - precision: 0.4963 - recall: 0.5105\n",
      "Epoch 87/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.4998 - precision: 0.4998 - recall: 0.4998\n",
      "Epoch 88/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4994 - precision: 0.4994 - recall: 0.4865\n",
      "Epoch 89/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5017 - precision: 0.5015 - recall: 0.5613\n",
      "Epoch 90/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4968 - precision: 0.4968 - recall: 0.4949\n",
      "Epoch 91/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4971 - precision: 0.4972 - recall: 0.5207\n",
      "Epoch 92/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4973 - precision: 0.4974 - recall: 0.5167\n",
      "Epoch 93/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4987 - precision: 0.4988 - recall: 0.5269\n",
      "Epoch 94/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.4991 - precision: 0.4991 - recall: 0.4931\n",
      "Epoch 95/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5020 - precision: 0.5019 - recall: 0.5344\n",
      "Epoch 96/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4995 - precision: 0.4995 - recall: 0.4851\n",
      "Epoch 97/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.4982 - precision: 0.4983 - recall: 0.5384\n",
      "Epoch 98/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6938 - accuracy: 0.5018 - precision: 0.5019 - recall: 0.4796\n",
      "Epoch 99/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6939 - accuracy: 0.5003 - precision: 0.5003 - recall: 0.4776\n",
      "Epoch 100/100\n",
      "2164/2164 [==============================] - 3s 1ms/step - loss: 0.6937 - accuracy: 0.5001 - precision: 0.5001 - recall: 0.4710\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_327/3101312666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# We have more Y=0 (NTA) than Y=1 (YTA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NTA (0)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"YTA (1)\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"plot_confusion_matrix only supports classifiers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m     cm = confusion_matrix(\n\u001b[1;32m    567\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \"\"\"\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \"\"\"\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=0.03),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "cv = KFold(n_splits=SPLITS, random_state=1, shuffle=True)\n",
    "\n",
    "\n",
    "test_scores = []\n",
    "for train, test in cv.split(X, y):\n",
    "    train_sampeled = sampling(y, kind=\"up\", indices=train, verbose=False)\n",
    "    \n",
    "    X_train = X[train_sampeled, :]\n",
    "    y_train = y[train_sampeled]\n",
    "    X_test = X[test, :]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=100)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # We have more Y=0 (NTA) than Y=1 (YTA)\n",
    "    metrics.plot_confusion_matrix(rfc, X_test, y_test)  \n",
    "    plt.show()\n",
    "    print(metrics.classification_report(y_test, y_pred, target_names=[\"NTA (0)\", \"YTA (1)\"]))\n",
    "    \n",
    "    # testing score\n",
    "    f1_test = metrics.f1_score(y_test, y_pred,average=\"weighted\")\n",
    "    acc_test = metrics.accuracy_score(y_test, y_pred)\n",
    "    test_scores.append([f1_test, acc_test])\n",
    "    \n",
    "    print(f\"F1 {f1_test}, accuracy {acc_test}\")\n",
    "    #print(\"----------\")\n",
    "    #print(f\"nr classes {list(set(y_test))}\")\n",
    "    # training score\n",
    "    #f1_train = metrics.f1_score(y_train, y_pred_train,)\n",
    "    #acc_train = metrics.accuracy_score(y_train, y_pred_train,)\n",
    "    #train_scores.append([f1_train,acc_train])\n",
    "    #Visualise training\n",
    "    rcParams['figure.figsize'] = (18, 8)\n",
    "    rcParams['axes.spines.top'] = False\n",
    "    rcParams['axes.spines.right'] = False\n",
    "    plt.plot(\n",
    "        np.arange(1, 101), \n",
    "        history.history['loss'], label='Loss'\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(1, 101), \n",
    "        history.history['accuracy'], label='Accuracy'\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(1, 101), \n",
    "        history.history['precision'], label='Precision'\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(1, 101), \n",
    "        history.history['recall'], label='Recall'\n",
    "    )\n",
    "    plt.title('Evaluation metrics', size=20)\n",
    "    plt.xlabel('Epoch', size=14)\n",
    "    plt.legend();\n",
    "    \n",
    "    \n",
    "test_scores = np.array(test_scores)\n",
    "print(f\"Average Test F1: {np.mean(test_scores[:,0])}, Test Accuracy: {np.mean(test_scores[:,1])}\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest feature importance (DEPRECATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (13,6)\n",
    "n_features_to_show = 30\n",
    "def feat_importance(forest, n_to_show):\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "    importances_index_desc = np.argsort(forest.feature_importances_)[::-1]\n",
    "\n",
    "    importance_sorted = forest.feature_importances_[importances_index_desc]\n",
    "    labels_sorted = [feat_name_lst[i] for i in importances_index_desc]\n",
    "    #std_sorted = [std[i] for i in importances_index_desc]\n",
    "\n",
    "    forest_importances = pd.Series(importance_sorted[:n_to_show], index=labels_sorted[:n_to_show])\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()\n",
    "    print(\"Plot done\")\n",
    "    \n",
    "def feat_importance_fix_cardinality(forest, X_test, y_test, n_to_show):\n",
    "    result = permutation_importance(forest, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "    importances_index_desc = np.argsort(result.importances_mean)[::-1]\n",
    "    importance_sorted = result.importances_mean[importances_index_desc]\n",
    "    labels_sorted = [feat_name_lst[i] for i in importances_index_desc]\n",
    "    std_sorted = result.importances_std[importances_index_desc]\n",
    "\n",
    "    forest_importances = pd.Series(importance_sorted, index=labels_sorted)[:n_to_show]\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std_sorted[:n_to_show], ax=ax)\n",
    "    #forest_importances.plot.bar(ax=ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model\")\n",
    "    ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"Cardinality done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_327/1707472750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#feat_importance_fix_cardinality(rfc, X_test, y_test, 50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_327/2430842062.py\u001b[0m in \u001b[0;36mfeat_importance\u001b[0;34m(forest, n_to_show)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_features_to_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeat_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_to_show\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mimportances_index_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "feat_importance(rfc, 50)\n",
    "#feat_importance_fix_cardinality(rfc, X_test, y_test, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print topic id & topic string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_nr</th>\n",
       "      <th>topic_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>im_dont_didnt_mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>friend_friends_im_relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>roommate_room_apartment_roommates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>dad_mom_mother_parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>work_job_boss_manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>birthday_christmas_party_family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>dog_cat_dogs_cats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>sister_shes_parents_mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>wife_husband_home_dont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>wedding_married_family_ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>brother_hes_parents_son</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>class_teacher_school_students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>game_play_playing_games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>racist_white_black_speak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>gay_trans_dont_friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>eat_food_vegan_eating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>hair_tattoo_art_im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>order_store_restaurant_didnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>funeral_grandma_grandmother_aunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>smoke_smoking_smoked_cigarettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>church_religion_religious_christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>music_song_band_songs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>post_sub_posts_asshole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>cousin_cousins_family_aunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>pregnant_baby_abortion_pregnancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>names_change_family_named</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>movie_watch_watching_movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>bathroom_toilet_shower_smell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>bus_seat_seats_train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_nr                            topic_str\n",
       "0         -1                    im_dont_didnt_mom\n",
       "1          0       friend_friends_im_relationship\n",
       "2          1    roommate_room_apartment_roommates\n",
       "3          2               dad_mom_mother_parents\n",
       "4          3                work_job_boss_manager\n",
       "5          4      birthday_christmas_party_family\n",
       "6          5                    dog_cat_dogs_cats\n",
       "7          6              sister_shes_parents_mom\n",
       "8          7               wife_husband_home_dont\n",
       "9          8          wedding_married_family_ring\n",
       "10         9              brother_hes_parents_son\n",
       "11        10        class_teacher_school_students\n",
       "12        11              game_play_playing_games\n",
       "13        12             racist_white_black_speak\n",
       "14        13               gay_trans_dont_friends\n",
       "15        14                eat_food_vegan_eating\n",
       "16        15                   hair_tattoo_art_im\n",
       "17        16         order_store_restaurant_didnt\n",
       "18        17     funeral_grandma_grandmother_aunt\n",
       "19        18      smoke_smoking_smoked_cigarettes\n",
       "20        19  church_religion_religious_christian\n",
       "21        20                music_song_band_songs\n",
       "22        21               post_sub_posts_asshole\n",
       "23        22           cousin_cousins_family_aunt\n",
       "24        23     pregnant_baby_abortion_pregnancy\n",
       "25        24            names_change_family_named\n",
       "26        25          movie_watch_watching_movies\n",
       "27        26         bathroom_toilet_shower_smell\n",
       "28        27                 bus_seat_seats_train"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_topics = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/helpers/topic_nr_to_str_24_11_2021.csv\")\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying things out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philipp/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (116,117) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/prepend_utc.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index                                                       128\n",
      "post_id                                                38946789\n",
      "post_text                                            1581032551\n",
      "post_num_comments                                       4945624\n",
      "writing_sty_past_abs                                    4945624\n",
      "writing_sty_present_abs                                 4945624\n",
      "writing_sty_future_abs                                  4945624\n",
      "writing_sty_past_norm                                   4945624\n",
      "writing_sty_present_norm                                4945624\n",
      "writing_sty_future_norm                                 4945624\n",
      "writing_sty_active_abs                                  4945624\n",
      "writing_sty_passive_abs                                 4945624\n",
      "writing_sty_active_norm                                 4945624\n",
      "writing_sty_passive_norm                                4945624\n",
      "writing_sty_sent_polarity                               4945624\n",
      "writing_sty_sent_subjectivity                           4945624\n",
      "writing_sty_focus_i_subj_abs                            4945624\n",
      "writing_sty_focus_you_sg_subj_abs                       4945624\n",
      "writing_sty_focus_he_subj_abs                           4945624\n",
      "writing_sty_focus_we_subj_abs                           4945624\n",
      "writing_sty_focus_you_pl_subj_abs                       4945624\n",
      "writing_sty_focus_they_subj_abs                         4945624\n",
      "writing_sty_focus_i_obj_abs                             4945624\n",
      "writing_sty_focus_you_sg_obj_abs                        4945624\n",
      "writing_sty_focus_he_obj_abs                            4945624\n",
      "writing_sty_focus_we_obj_abs                            4945624\n",
      "writing_sty_focus_you_pl_obj_abs                        4945624\n",
      "writing_sty_focus_they_obj_abs                          4945624\n",
      "writing_sty_focus_i_poss_abs                            4945624\n",
      "writing_sty_focus_you_sg_poss_abs                       4945624\n",
      "writing_sty_focus_he_poss_abs                           4945624\n",
      "writing_sty_focus_we_poss_abs                           4945624\n",
      "writing_sty_focus_you_pl_poss_abs                       4945624\n",
      "writing_sty_focus_they_poss_abs                         4945624\n",
      "writing_sty_focus_i_subj_norm                           4945624\n",
      "writing_sty_focus_you_sg_subj_norm                      4945624\n",
      "writing_sty_focus_he_subj_norm                          4945624\n",
      "writing_sty_focus_we_subj_norm                          4945624\n",
      "writing_sty_focus_you_pl_subj_norm                      4945624\n",
      "writing_sty_focus_they_subj_norm                        4945624\n",
      "writing_sty_focus_i_obj_norm                            4945624\n",
      "writing_sty_focus_you_sg_obj_norm                       4945624\n",
      "writing_sty_focus_he_obj_norm                           4945624\n",
      "writing_sty_focus_we_obj_norm                           4945624\n",
      "writing_sty_focus_you_pl_obj_norm                       4945624\n",
      "writing_sty_focus_they_obj_norm                         4945624\n",
      "writing_sty_focus_i_poss_norm                           4945624\n",
      "writing_sty_focus_you_sg_poss_norm                      4945624\n",
      "writing_sty_focus_he_poss_norm                          4945624\n",
      "writing_sty_focus_we_poss_norm                          4945624\n",
      "writing_sty_focus_you_pl_poss_norm                      4945624\n",
      "writing_sty_focus_they_poss_norm                        4945624\n",
      "writing_sty_self_fear_norm                              4945624\n",
      "writing_sty_self_anger_norm                             4945624\n",
      "writing_sty_self_trust_norm                             4945624\n",
      "writing_sty_self_surprise_norm                          4945624\n",
      "writing_sty_self_sadness_norm                           4945624\n",
      "writing_sty_self_disgust_norm                           4945624\n",
      "writing_sty_self_joy_norm                               4945624\n",
      "writing_sty_self_anticipation_norm                      4945624\n",
      "writing_sty_self_positive_norm                          4945624\n",
      "writing_sty_self_negative_norm                          4945624\n",
      "writing_sty_other_fear_norm                             4945624\n",
      "writing_sty_other_anger_norm                            4945624\n",
      "writing_sty_other_trust_norm                            4945624\n",
      "writing_sty_other_surprise_norm                         4945624\n",
      "writing_sty_other_sadness_norm                          4945624\n",
      "writing_sty_other_disgust_norm                          4945624\n",
      "writing_sty_other_joy_norm                              4945624\n",
      "writing_sty_other_anticipation_norm                     4945624\n",
      "writing_sty_other_positive_norm                         4945624\n",
      "writing_sty_other_negative_norm                         4945624\n",
      "writing_sty_self_prof                                   4945624\n",
      "writing_sty_other_prof                                  4945624\n",
      "reactions_YTA                                           4945624\n",
      "reactions_NTA                                           4945624\n",
      "reactions_INFO                                          4945624\n",
      "reactions_ESH                                           4945624\n",
      "reactions_NAH                                           4945624\n",
      "reactions_weighted_YTA                                  4945624\n",
      "reactions_weighted_NTA                                  4945624\n",
      "reactions_weighted_INFO                                 4945624\n",
      "reactions_weighted_ESH                                  4945624\n",
      "reactions_weighted_NAH                                  4945624\n",
      "speaker_author_age                                      4945624\n",
      "speaker_author_gender                                   4945624\n",
      "writing_sty_!_count                                     4945624\n",
      "writing_sty_\"_count                                     4945624\n",
      "writing_sty_?_count                                     4945624\n",
      "writing_sty_anticipation_abs                            4945624\n",
      "writing_sty_joy_abs                                     4945624\n",
      "writing_sty_positive_abs                                4945624\n",
      "writing_sty_surprise_abs                                4945624\n",
      "writing_sty_trust_abs                                   4945624\n",
      "writing_sty_anger_abs                                   4945624\n",
      "writing_sty_fear_abs                                    4945624\n",
      "writing_sty_negative_abs                                4945624\n",
      "writing_sty_sadness_abs                                 4945624\n",
      "writing_sty_disgust_abs                                 4945624\n",
      "writing_sty_anticipation_norm                           4945624\n",
      "writing_sty_joy_norm                                    4945624\n",
      "writing_sty_positive_norm                               4945624\n",
      "writing_sty_surprise_norm                               4945624\n",
      "writing_sty_trust_norm                                  4945624\n",
      "writing_sty_anger_norm                                  4945624\n",
      "writing_sty_fear_norm                                   4945624\n",
      "writing_sty_negative_norm                               4945624\n",
      "writing_sty_sadness_norm                                4945624\n",
      "writing_sty_disgust_norm                                4945624\n",
      "writing_sty_aita_count                                  4945624\n",
      "writing_sty_aita_avg_location                           4945624\n",
      "writing_sty_aita_fst_location                           4945624\n",
      "writing_sty_aita_lst_location                           4945624\n",
      "writing_sty_profanity_abs                               4945624\n",
      "writing_sty_profanity_norm                              4945624\n",
      "writing_sty_is_wibta                                    4945624\n",
      "topic_nr                                                4945624\n",
      "reactions_is_angel                                     20138428\n",
      "reactions_is_devil                                     20114264\n",
      "speaker_account_age                                     4945624\n",
      "speaker_account_comment_karma                           4945624\n",
      "speaker_account_link_karma                              4945624\n",
      "liwc_WC                                                 4945624\n",
      "liwc_Analytic                                           4945624\n",
      "liwc_Clout                                              4945624\n",
      "liwc_Authentic                                          4945624\n",
      "liwc_Tone                                               4945624\n",
      "liwc_WPS                                                4945624\n",
      "liwc_Sixltr                                             4945624\n",
      "liwc_Dic                                                4945624\n",
      "liwc_function                                           4945624\n",
      "liwc_pronoun                                            4945624\n",
      "liwc_ppron                                              4945624\n",
      "liwc_i                                                  4945624\n",
      "liwc_we                                                 4945624\n",
      "liwc_you                                                4945624\n",
      "liwc_shehe                                              4945624\n",
      "liwc_they                                               4945624\n",
      "liwc_ipron                                              4945624\n",
      "liwc_article                                            4945624\n",
      "liwc_prep                                               4945624\n",
      "liwc_auxverb                                            4945624\n",
      "liwc_adverb                                             4945624\n",
      "liwc_conj                                               4945624\n",
      "liwc_negate                                             4945624\n",
      "liwc_verb                                               4945624\n",
      "liwc_adj                                                4945624\n",
      "liwc_compare                                            4945624\n",
      "liwc_interrog                                           4945624\n",
      "liwc_number                                             4945624\n",
      "liwc_quant                                              4945624\n",
      "liwc_affect                                             4945624\n",
      "liwc_posemo                                             4945624\n",
      "liwc_negemo                                             4945624\n",
      "liwc_anx                                                4945624\n",
      "liwc_anger                                              4945624\n",
      "liwc_sad                                                4945624\n",
      "liwc_social                                             4945624\n",
      "liwc_family                                             4945624\n",
      "liwc_friend                                             4945624\n",
      "liwc_female                                             4945624\n",
      "liwc_male                                               4945624\n",
      "liwc_cogproc                                            4945624\n",
      "liwc_insight                                            4945624\n",
      "liwc_cause                                              4945624\n",
      "liwc_discrep                                            4945624\n",
      "liwc_tentat                                             4945624\n",
      "liwc_certain                                            4945624\n",
      "liwc_differ                                             4945624\n",
      "liwc_percept                                            4945624\n",
      "liwc_see                                                4945624\n",
      "liwc_hear                                               4945624\n",
      "liwc_feel                                               4945624\n",
      "liwc_bio                                                4945624\n",
      "liwc_body                                               4945624\n",
      "liwc_health                                             4945624\n",
      "liwc_sexual                                             4945624\n",
      "liwc_ingest                                             4945624\n",
      "liwc_drives                                             4945624\n",
      "liwc_affiliation                                        4945624\n",
      "liwc_achieve                                            4945624\n",
      "liwc_power                                              4945624\n",
      "liwc_reward                                             4945624\n",
      "liwc_risk                                               4945624\n",
      "liwc_focuspast                                          4945624\n",
      "liwc_focuspresent                                       4945624\n",
      "liwc_focusfuture                                        4945624\n",
      "liwc_relativ                                            4945624\n",
      "liwc_motion                                             4945624\n",
      "liwc_space                                              4945624\n",
      "liwc_time                                               4945624\n",
      "liwc_work                                               4945624\n",
      "liwc_leisure                                            4945624\n",
      "liwc_home                                               4945624\n",
      "liwc_money                                              4945624\n",
      "liwc_relig                                              4945624\n",
      "liwc_death                                              4945624\n",
      "liwc_informal                                           4945624\n",
      "liwc_swear                                              4945624\n",
      "liwc_netspeak                                           4945624\n",
      "liwc_assent                                             4945624\n",
      "liwc_nonflu                                             4945624\n",
      "liwc_filler                                             4945624\n",
      "liwc_AllPunc                                            4945624\n",
      "liwc_Period                                             4945624\n",
      "liwc_Comma                                              4945624\n",
      "liwc_Colon                                              4945624\n",
      "liwc_SemiC                                              4945624\n",
      "liwc_QMark                                              4945624\n",
      "liwc_Exclam                                             4945624\n",
      "liwc_Dash                                               4945624\n",
      "liwc_Quote                                              4945624\n",
      "liwc_Apostro                                            4945624\n",
      "liwc_Parenth                                            4945624\n",
      "liwc_OtherP                                             4945624\n",
      "foundations_WC                                          4945624\n",
      "foundations_WPS                                         4945624\n",
      "foundations_Sixltr                                      4945624\n",
      "foundations_Dic                                         4945624\n",
      "foundations_01                    HarmVirtue            4945624\n",
      "foundations_02                    HarmVice              4945624\n",
      "foundations_03                    FairnessVirtue        4945624\n",
      "foundations_04                    FairnessVice          4945624\n",
      "foundations_05                    IngroupVirtue         4945624\n",
      "foundations_06                    IngroupVice           4945624\n",
      "foundations_07                    AuthorityVirtue       4945624\n",
      "foundations_08                    AuthorityVice         4945624\n",
      "foundations_09                    PurityVirtue          4945624\n",
      "foundations_10                    PurityVice            4945624\n",
      "foundations_11                    MoralityGeneral       4945624\n",
      "foundations_AllPunc                                     4945624\n",
      "foundations_Period                                      4945624\n",
      "foundations_Comma                                       4945624\n",
      "foundations_Colon                                       4945624\n",
      "foundations_SemiC                                       4945624\n",
      "foundations_QMark                                       4945624\n",
      "foundations_Exclam                                      4945624\n",
      "foundations_Dash                                        4945624\n",
      "foundations_Quote                                       4945624\n",
      "foundations_Apostro                                     4945624\n",
      "foundations_Parenth                                     4945624\n",
      "foundations_OtherP                                      4945624\n",
      "YTA_ratio                                               4945624\n",
      "post_created_utc                                        4945624\n"
     ]
    }
   ],
   "source": [
    "print(df.memory_usage(deep=True).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_284/891300131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reactions_is_angel\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5813\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5814\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5815\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5816\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     def convert(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'False'"
     ]
    }
   ],
   "source": [
    "df.replace({False: 0, True: 1}, inplace=True)\n",
    "df = df[\"reactions_is_angel\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"reactions_is_angel\"].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "a = df['reactions_is_devil'].unique()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reactions_is_devil'] = df['reactions_is_devil'].replace(\"False\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/prepend_utc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>2.59GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_train</th>\n",
       "      <td>141.91MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_test</th>\n",
       "      <td>48.83MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_train</th>\n",
       "      <td>724.11KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_sampeled</th>\n",
       "      <td>724.11KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>565.36KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>278.69KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_pred</th>\n",
       "      <td>249.23KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test</th>\n",
       "      <td>249.23KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i5</th>\n",
       "      <td>5.92KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Size\n",
       "df                2.59GB\n",
       "X_train         141.91MB\n",
       "X_test           48.83MB\n",
       "y_train         724.11KB\n",
       "train_sampeled  724.11KB\n",
       "train           565.36KB\n",
       "test            278.69KB\n",
       "y_pred          249.23KB\n",
       "y_test          249.23KB\n",
       "_i5               5.92KB"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obj_size_fmt(num):\n",
    "    if num<10**3:\n",
    "        return \"{:.2f}{}\".format(num,\"B\")\n",
    "    elif ((num>=10**3)&(num<10**6)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**3),\"KB\")\n",
    "    elif ((num>=10**6)&(num<10**9)):\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**6),\"MB\")\n",
    "    else:\n",
    "        return \"{:.2f}{}\".format(num/(1.024*10**9),\"GB\")\n",
    "\n",
    "\n",
    "def memory_usage():\n",
    "    memory_usage_by_variable=pd.DataFrame({k:sys.getsizeof(v)\\\n",
    "    for (k,v) in globals().items()},index=['Size'])\n",
    "    memory_usage_by_variable=memory_usage_by_variable.T\n",
    "    memory_usage_by_variable=memory_usage_by_variable.sort_values(by='Size',ascending=False).head(10)\n",
    "    memory_usage_by_variable['Size']=memory_usage_by_variable['Size'].apply(lambda x: obj_size_fmt(x))\n",
    "    return memory_usage_by_variable\n",
    "\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df</th>\n",
       "      <td>2.49GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_train</th>\n",
       "      <td>114.53MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X_test</th>\n",
       "      <td>56.41MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>715.63KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_train</th>\n",
       "      <td>654.52KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>352.81KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test</th>\n",
       "      <td>322.43KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i6</th>\n",
       "      <td>8.28KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_ii</th>\n",
       "      <td>8.28KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i5</th>\n",
       "      <td>3.08KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Size\n",
       "df         2.49GB\n",
       "X_train  114.53MB\n",
       "X_test    56.41MB\n",
       "train    715.63KB\n",
       "y_train  654.52KB\n",
       "test     352.81KB\n",
       "y_test   322.43KB\n",
       "_i6        8.28KB\n",
       "_ii        8.28KB\n",
       "_i5        3.08KB"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finally check memory usage\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>715.63KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>352.81KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i6</th>\n",
       "      <td>8.28KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_iii</th>\n",
       "      <td>8.28KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i5</th>\n",
       "      <td>3.08KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i4</th>\n",
       "      <td>2.28KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i3</th>\n",
       "      <td>2.17KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i2</th>\n",
       "      <td>1.47KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>1.44KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_name_lst</th>\n",
       "      <td>1.42KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Size\n",
       "train                  715.63KB\n",
       "test                   352.81KB\n",
       "_i6                      8.28KB\n",
       "_iii                     8.28KB\n",
       "_i5                      3.08KB\n",
       "_i4                      2.28KB\n",
       "_i3                      2.17KB\n",
       "_i2                      1.47KB\n",
       "RandomForestRegressor    1.44KB\n",
       "feat_name_lst            1.42KB"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "del X_train\n",
    "del X_test\n",
    "del y_train\n",
    "del y_test\n",
    "#triggering collection\n",
    "gc.collect()\n",
    "\n",
    "#finally check memory usage\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['post_id', 'foundations_post_id', 'foundations_WC', 'foundations_WPS', 'foundations_Sixltr', 'foundations_Dic', 'foundations_01 HarmVirtue', 'foundations_02 HarmVice', 'foundations_03 FairnessVirtue', 'foundations_04 FairnessVice', 'foundations_05 IngroupVirtue', 'foundations_06 IngroupVice', 'foundations_07 AuthorityVirtue', 'foundations_08 AuthorityVice', 'foundations_09 PurityVirtue', 'foundations_10 PurityVice', 'foundations_11 MoralityGeneral', 'foundations_AllPunc', 'foundations_Period', 'foundations_Comma', 'foundations_Colon', 'foundations_SemiC', 'foundations_QMark', 'foundations_Exclam', 'foundations_Dash', 'foundations_Quote', 'foundations_Apostro', 'foundations_Parenth', 'foundations_OtherP', 'foundations_title_post_id', 'foundations_title_WC', 'foundations_title_WPS', 'foundations_title_Sixltr', 'foundations_title_Dic', 'foundations_title_01 HarmVirtue', 'foundations_title_02 HarmVice', 'foundations_title_03 FairnessVirtue', 'foundations_title_04 FairnessVice', 'foundations_title_05 IngroupVirtue', 'foundations_title_06 IngroupVice', 'foundations_title_07 AuthorityVirtue', 'foundations_title_08 AuthorityVice', 'foundations_title_09 PurityVirtue', 'foundations_title_10 PurityVice', 'foundations_title_11 MoralityGeneral', 'foundations_title_AllPunc', 'foundations_title_Period', 'foundations_title_Comma', 'foundations_title_Colon', 'foundations_title_SemiC', 'foundations_title_QMark', 'foundations_title_Exclam', 'foundations_title_Dash', 'foundations_title_Quote', 'foundations_title_Apostro', 'foundations_title_Parenth', 'foundations_title_OtherP']\n",
      "(618203, 57)\n"
     ]
    }
   ],
   "source": [
    "df_std = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/standalone.csv\", nrows=3)\n",
    "#cols_to_read = list(df_std.columns).remove(\"post_text\")\n",
    "liwc_cols = [\"liwc_post_id\", \"liwc_title_post_id\"]\n",
    "mf_cols = [\"foundation_post_id\", \"foundations_title_post_id\"]\n",
    "#cols_to_read = list(filter(lambda x: (not x == \"post_text\") and (not x in liwc_cols) and (not x in mf_cols) , list(df_std.columns)))\n",
    "cols_to_read = list(filter(lambda x: \"foundation\" in x.lower() or x.lower() == \"post_id\" , list(df_std.columns)))\n",
    "print(cols_to_read)\n",
    "df_std = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/standalone.csv\", usecols=cols_to_read)\n",
    "\n",
    "#print(list(df_std.columns))\n",
    "#memory_usage()\n",
    "print(df_std.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['post_id', 'foundations_post_id', 'foundations_WC', 'foundations_WPS', 'foundations_Sixltr', 'foundations_Dic', 'foundations_01 HarmVirtue', 'foundations_02 HarmVice', 'foundations_03 FairnessVirtue', 'foundations_04 FairnessVice', 'foundations_05 IngroupVirtue', 'foundations_06 IngroupVice', 'foundations_07 AuthorityVirtue', 'foundations_08 AuthorityVice', 'foundations_09 PurityVirtue', 'foundations_10 PurityVice', 'foundations_11 MoralityGeneral', 'foundations_AllPunc', 'foundations_Period', 'foundations_Comma', 'foundations_Colon', 'foundations_SemiC', 'foundations_QMark', 'foundations_Exclam', 'foundations_Dash', 'foundations_Quote', 'foundations_Apostro', 'foundations_Parenth', 'foundations_OtherP', 'foundations_title_post_id', 'foundations_title_WC', 'foundations_title_WPS', 'foundations_title_Sixltr', 'foundations_title_Dic', 'foundations_title_01 HarmVirtue', 'foundations_title_02 HarmVice', 'foundations_title_03 FairnessVirtue', 'foundations_title_04 FairnessVice', 'foundations_title_05 IngroupVirtue', 'foundations_title_06 IngroupVice', 'foundations_title_07 AuthorityVirtue', 'foundations_title_08 AuthorityVice', 'foundations_title_09 PurityVirtue', 'foundations_title_10 PurityVice', 'foundations_title_11 MoralityGeneral', 'foundations_title_AllPunc', 'foundations_title_Period', 'foundations_title_Comma', 'foundations_title_Colon', 'foundations_title_SemiC', 'foundations_title_QMark', 'foundations_title_Exclam', 'foundations_title_Dash', 'foundations_title_Quote', 'foundations_title_Apostro', 'foundations_title_Parenth', 'foundations_title_OtherP']\n"
     ]
    }
   ],
   "source": [
    "print(list(df_std.columns))\n",
    "df_std.to_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/standalone/foundations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618203, 123)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_std</th>\n",
       "      <td>1.73GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_prepend</th>\n",
       "      <td>627.26MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_iii</th>\n",
       "      <td>2.89KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i5</th>\n",
       "      <td>2.89KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i8</th>\n",
       "      <td>2.65KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i4</th>\n",
       "      <td>2.28KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i3</th>\n",
       "      <td>2.17KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_i2</th>\n",
       "      <td>1.47KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_7</th>\n",
       "      <td>1.26KB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_</th>\n",
       "      <td>1.26KB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Size\n",
       "df_std        1.73GB\n",
       "df_prepend  627.26MB\n",
       "_iii          2.89KB\n",
       "_i5           2.89KB\n",
       "_i8           2.65KB\n",
       "_i4           2.28KB\n",
       "_i3           2.17KB\n",
       "_i2           1.47KB\n",
       "_7            1.26KB\n",
       "_             1.26KB"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepend = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/prepend_utc.csv\", nrows=3)\n",
    "liwc_cols = ['liwc_WC', 'liwc_Analytic', 'liwc_Clout', 'liwc_Authentic', 'liwc_Tone', 'liwc_WPS', 'liwc_Sixltr', 'liwc_Dic', 'liwc_function', 'liwc_pronoun', 'liwc_ppron', 'liwc_i', 'liwc_we', 'liwc_you', 'liwc_shehe', 'liwc_they', 'liwc_ipron', 'liwc_article', 'liwc_prep', 'liwc_auxverb', 'liwc_adverb', 'liwc_conj', 'liwc_negate', 'liwc_verb', 'liwc_adj', 'liwc_compare', 'liwc_interrog', 'liwc_number', 'liwc_quant', 'liwc_affect', 'liwc_posemo', 'liwc_negemo', 'liwc_anx', 'liwc_anger', 'liwc_sad', 'liwc_social', 'liwc_family', 'liwc_friend', 'liwc_female', 'liwc_male', 'liwc_cogproc', 'liwc_insight', 'liwc_cause', 'liwc_discrep', 'liwc_tentat', 'liwc_certain', 'liwc_differ', 'liwc_percept', 'liwc_see', 'liwc_hear', 'liwc_feel', 'liwc_bio', 'liwc_body', 'liwc_health', 'liwc_sexual', 'liwc_ingest', 'liwc_drives', 'liwc_affiliation', 'liwc_achieve', 'liwc_power', 'liwc_reward', 'liwc_risk', 'liwc_focuspast', 'liwc_focuspresent', 'liwc_focusfuture', 'liwc_relativ', 'liwc_motion', 'liwc_space', 'liwc_time', 'liwc_work', 'liwc_leisure', 'liwc_home', 'liwc_money', 'liwc_relig', 'liwc_death', 'liwc_informal', 'liwc_swear', 'liwc_netspeak', 'liwc_assent', 'liwc_nonflu', 'liwc_filler', 'liwc_AllPunc', 'liwc_Period', 'liwc_Comma', 'liwc_Colon', 'liwc_SemiC', 'liwc_QMark', 'liwc_Exclam', 'liwc_Dash', 'liwc_Quote', 'liwc_Apostro', 'liwc_Parenth', 'liwc_OtherP']\n",
    "mf_cols = ['foundations_WC', 'foundations_WPS', 'foundations_Sixltr', 'foundations_Dic', 'foundations_01                    HarmVirtue', 'foundations_02                    HarmVice', 'foundations_03                    FairnessVirtue', 'foundations_04                    FairnessVice', 'foundations_05                    IngroupVirtue', 'foundations_06                    IngroupVice', 'foundations_07                    AuthorityVirtue', 'foundations_08                    AuthorityVice', 'foundations_09                    PurityVirtue', 'foundations_10                    PurityVice', 'foundations_11                    MoralityGeneral', 'foundations_AllPunc', 'foundations_Period', 'foundations_Comma', 'foundations_Colon', 'foundations_SemiC', 'foundations_QMark', 'foundations_Exclam', 'foundations_Dash', 'foundations_Quote', 'foundations_Apostro', 'foundations_Parenth', 'foundations_OtherP']\n",
    "cols_to_read = list(filter(lambda x: (not x == \"post_text\") and (not x in liwc_cols) and (not x in mf_cols) , list(df_prepend.columns)))\n",
    "df_prepend = pd.read_csv(\"/mnt/g/My Drive/Msc/Thesis/Coding/dataset_output/prepend_utc.csv\", usecols=cols_to_read)\n",
    "print(df_prepend.shape)\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df_prepend.columns))\n",
    "print(list(df_std.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['liwc_WC', 'liwc_Analytic', 'liwc_Clout', 'liwc_Authentic', 'liwc_Tone', 'liwc_WPS', 'liwc_Sixltr', 'liwc_Dic', 'liwc_function', 'liwc_pronoun', 'liwc_ppron', 'liwc_i', 'liwc_we', 'liwc_you', 'liwc_shehe', 'liwc_they', 'liwc_ipron', 'liwc_article', 'liwc_prep', 'liwc_auxverb', 'liwc_adverb', 'liwc_conj', 'liwc_negate', 'liwc_verb', 'liwc_adj', 'liwc_compare', 'liwc_interrog', 'liwc_number', 'liwc_quant', 'liwc_affect', 'liwc_posemo', 'liwc_negemo', 'liwc_anx', 'liwc_anger', 'liwc_sad', 'liwc_social', 'liwc_family', 'liwc_friend', 'liwc_female', 'liwc_male', 'liwc_cogproc', 'liwc_insight', 'liwc_cause', 'liwc_discrep', 'liwc_tentat', 'liwc_certain', 'liwc_differ', 'liwc_percept', 'liwc_see', 'liwc_hear', 'liwc_feel', 'liwc_bio', 'liwc_body', 'liwc_health', 'liwc_sexual', 'liwc_ingest', 'liwc_drives', 'liwc_affiliation', 'liwc_achieve', 'liwc_power', 'liwc_reward', 'liwc_risk', 'liwc_focuspast', 'liwc_focuspresent', 'liwc_focusfuture', 'liwc_relativ', 'liwc_motion', 'liwc_space', 'liwc_time', 'liwc_work', 'liwc_leisure', 'liwc_home', 'liwc_money', 'liwc_relig', 'liwc_death', 'liwc_informal', 'liwc_swear', 'liwc_netspeak', 'liwc_assent', 'liwc_nonflu', 'liwc_filler', 'liwc_AllPunc', 'liwc_Period', 'liwc_Comma', 'liwc_Colon', 'liwc_SemiC', 'liwc_QMark', 'liwc_Exclam', 'liwc_Dash', 'liwc_Quote', 'liwc_Apostro', 'liwc_Parenth', 'liwc_OtherP']\n",
      "['foundations_WC', 'foundations_WPS', 'foundations_Sixltr', 'foundations_Dic', 'foundations_01                    HarmVirtue', 'foundations_02                    HarmVice', 'foundations_03                    FairnessVirtue', 'foundations_04                    FairnessVice', 'foundations_05                    IngroupVirtue', 'foundations_06                    IngroupVice', 'foundations_07                    AuthorityVirtue', 'foundations_08                    AuthorityVice', 'foundations_09                    PurityVirtue', 'foundations_10                    PurityVice', 'foundations_11                    MoralityGeneral', 'foundations_AllPunc', 'foundations_Period', 'foundations_Comma', 'foundations_Colon', 'foundations_SemiC', 'foundations_QMark', 'foundations_Exclam', 'foundations_Dash', 'foundations_Quote', 'foundations_Apostro', 'foundations_Parenth', 'foundations_OtherP']\n",
      "(618203, 244)\n"
     ]
    }
   ],
   "source": [
    "liwc = list(filter(lambda x: \"liwc\" in x.lower(), df_prepend))\n",
    "mf = list(filter(lambda x: \"foundation\" in x.lower(), df_prepend))\n",
    "print(liwc)\n",
    "print(mf)\n",
    "print(df_prepend.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         19\n",
      "1          6\n",
      "2          2\n",
      "3         22\n",
      "4          9\n",
      "          ..\n",
      "618198     7\n",
      "618199     5\n",
      "618200     7\n",
      "618201     1\n",
      "618202     1\n",
      "Name: writing_sty_past_abs, Length: 618203, dtype: int64\n",
      "0          5\n",
      "1         13\n",
      "2         16\n",
      "3         10\n",
      "4          1\n",
      "          ..\n",
      "618198     4\n",
      "618199    17\n",
      "618200    16\n",
      "618201     7\n",
      "618202     3\n",
      "Name: writing_sty_past_abs, Length: 618203, dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'title_writing_sty_past_abs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title_writing_sty_past_abs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108/391228081.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_prepend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"writing_sty_past_abs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"writing_sty_past_abs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_std\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title_writing_sty_past_abs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title_writing_sty_past_abs'"
     ]
    }
   ],
   "source": [
    "print(df_prepend[\"writing_sty_past_abs\"])\n",
    "print(df_std[\"writing_sty_past_abs\"])\n",
    "print(df_std[\"title_writing_sty_past_abs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = df_std.merge(df_prepend, left_on=\"post_id\", right_on=\"post_id\", validate=\"1:1\",suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference opposite & clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataframes: 1\n",
      "(400000, 192)\n"
     ]
    }
   ],
   "source": [
    "dfs, acros = get_data(normalised=0, weighted=True, title_prepend=0, topics_separate=False)\n",
    "print(dfs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df original shape (400000, 192)\n",
      "info sum 0\n",
      "Removed 394739 rows b.c. no votes. Now (5261, 197)\n",
      "Removed 0 rows b.c. not enough agreement. Now (5261, 197)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['post_created_utc'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_464/3313156804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_name_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macros\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ratio\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjudgement_weighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"opposite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_464/1375992481.py\u001b[0m in \u001b[0;36mget_data_classes\u001b[0;34m(df, acros, ratio, verbose, predict, judgement_weighted, mapping)\u001b[0m\n\u001b[1;32m     48\u001b[0m      \u001b[0;31m# get list of all columns that contain uppercase vote acronym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mvote_acroynms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0macr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvote_acroynms\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"post_text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"post_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"post_created_utc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unnamed: 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Removing top 4 most important features leads to 0.66 f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4899\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4900\u001b[0m         \"\"\"\n\u001b[0;32m-> 4901\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4902\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4903\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4145\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4147\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4180\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['post_created_utc'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = dfs[0]\n",
    "X, y, feat_name_lst = get_data_classes(df, ratio=0.5, acros=acros, predict=\"ratio\",judgement_weighted=True, mapping=\"opposite\", verbose=True)    \n",
    "train, test = train_test_split(range(len(X)), test_size=0.33, random_state=42)\n",
    "X_train = X[train, :]\n",
    "y_train = y[train]\n",
    "X_test = X[test, :]\n",
    "y_test = y[test]\n",
    "\n",
    "\n",
    "plt.hist(y[train], bins=10*32)\n",
    "plt.show()\n",
    "\n",
    "oppoiste_y = y[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df original shape (400000, 191)\n",
      "info sum 0\n",
      "Removed 301987 rows b.c. no votes. Now (98013, 191)\n",
      "Removed 0 rows b.c. not enough agreement. Now (98013, 191)\n",
      "(98013, 176)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = dfs[0]\n",
    "X, y, feat_name_lst = get_data_classes(df, ratio=0.5, acros=acros, predict=\"ratio\",judgement_weighted=True, mapping=\"clip\", verbose=True)    \n",
    "train, test = train_test_split(range(len(X)), test_size=0.33, random_state=42)\n",
    "X_train = X[train, :]\n",
    "y_train = y[train]\n",
    "X_test = X[test, :]\n",
    "y_test = y[test]\n",
    "\n",
    "clip_y = y[\"train\"]\n",
    "plt.hist(y[train], bins=10*32)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(clip_y, oppoiste_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
